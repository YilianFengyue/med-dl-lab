"""
CNNè®­ç»ƒæ¨¡å—
"""
import torch
import torch.nn as nn
from tqdm import tqdm
import matplotlib.pyplot as plt
from config import *
from dataset import load_data, add_noise
from models import Autoencoder, CNN


def train_cnn(train_loader, test_loader, autoencoder):
    """è®­ç»ƒCNNåˆ†ç±»å™¨"""
    print("\n" + "=" * 60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒCNNåˆ†ç±»å™¨")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = CNN().to(DEVICE)
    autoencoder.eval()  # è‡ªç¼–ç å™¨è®¾ä¸ºè¯„ä¼°æ¨¡å¼
    
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=CNN_LR)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='max', factor=0.5, patience=5, verbose=True
    )
    
    # è®°å½•è®­ç»ƒè¿‡ç¨‹
    history = {
        'train_loss': [], 'train_acc': [],
        'test_loss': [], 'test_acc': []
    }
    
    best_acc = 0.0
    
    for epoch in range(CNN_EPOCHS):
        # ==================== è®­ç»ƒé˜¶æ®µ ====================
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1:02d}/{CNN_EPOCHS}")
        for data, label in pbar:
            data, label = data.to(DEVICE), label.to(DEVICE)
            
            # æ·»åŠ å™ªå£°å¹¶é€šè¿‡è‡ªç¼–ç å™¨å»å™ª
            noisy_data = add_noise(data)
            with torch.no_grad():
                denoised_data = autoencoder(noisy_data)
            
            optimizer.zero_grad()
            output = model(denoised_data)
            loss = criterion(output, label)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            train_correct += pred.eq(label.view_as(pred)).sum().item()
            train_total += label.size(0)
            
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'acc': f'{100. * train_correct / train_total:.1f}%'
            })
        
        avg_train_loss = train_loss / len(train_loader)
        train_acc = 100. * train_correct / train_total
        history['train_loss'].append(avg_train_loss)
        history['train_acc'].append(train_acc)
        
        # ==================== æµ‹è¯•é˜¶æ®µ ====================
        model.eval()
        test_loss = 0.0
        test_correct = 0
        test_total = 0
        
        with torch.no_grad():
            for data, label in test_loader:
                data, label = data.to(DEVICE), label.to(DEVICE)
                
                # æµ‹è¯•é›†å·²æœ‰å™ªå£°ï¼Œç›´æ¥é€šè¿‡è‡ªç¼–ç å™¨
                denoised_data = autoencoder(data)
                output = model(denoised_data)
                
                test_loss += criterion(output, label).item()
                pred = output.argmax(dim=1, keepdim=True)
                test_correct += pred.eq(label.view_as(pred)).sum().item()
                test_total += label.size(0)
        
        avg_test_loss = test_loss / len(test_loader)
        test_acc = 100. * test_correct / test_total
        history['test_loss'].append(avg_test_loss)
        history['test_acc'].append(test_acc)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step(test_acc)
        
        # æ‰“å°ç»“æœ
        print(f"[CNN] Epoch {epoch+1:02d}/{CNN_EPOCHS} | "
              f"Train Loss: {avg_train_loss:.4f} Acc: {train_acc:.2f}% | "
              f"Test Loss: {avg_test_loss:.4f} Acc: {test_acc:.2f}%")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if test_acc > best_acc:
            best_acc = test_acc
            torch.save(model.state_dict(), MODEL_DIR / "cnn_best.pth")
            print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (acc: {best_acc:.2f}%)")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    torch.save(model.state_dict(), MODEL_DIR / "cnn_final.pth")
    print(f"\nâœ… CNNè®­ç»ƒå®Œæˆï¼æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
    
    return model, history


def plot_cnn_history(history):
    """ç»˜åˆ¶CNNè®­ç»ƒå†å²"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    epochs = range(1, len(history['train_loss']) + 1)
    
    # Lossæ›²çº¿
    axes[0].plot(epochs, history['train_loss'], 'b-o', label='Train Loss', markersize=4)
    axes[0].plot(epochs, history['test_loss'], 'r-o', label='Test Loss', markersize=4)
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Cross Entropy Loss', fontsize=12)
    axes[0].set_title('CNN Training Loss', fontsize=14, fontweight='bold')
    axes[0].legend(fontsize=11)
    axes[0].grid(True, linestyle='--', alpha=0.7)
    
    # Accuracyæ›²çº¿
    axes[1].plot(epochs, history['train_acc'], 'b-o', label='Train Acc', markersize=4)
    axes[1].plot(epochs, history['test_acc'], 'r-o', label='Test Acc', markersize=4)
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Accuracy (%)', fontsize=12)
    axes[1].set_title('CNN Training Accuracy', fontsize=14, fontweight='bold')
    axes[1].legend(fontsize=11)
    axes[1].grid(True, linestyle='--', alpha=0.7)
    axes[1].set_ylim([0, 105])
    
    # æ ‡æ³¨æœ€ä½³ç‚¹
    best_idx = history['test_acc'].index(max(history['test_acc']))
    axes[1].annotate(f'Best: {history["test_acc"][best_idx]:.1f}%',
                    xy=(best_idx + 1, history['test_acc'][best_idx]),
                    xytext=(best_idx + 3, history['test_acc'][best_idx] - 10),
                    arrowprops=dict(arrowstyle='->', color='red'),
                    fontsize=10, color='red')
    
    plt.tight_layout()
    plt.savefig(FIGURE_DIR / "cnn_training_history.png", dpi=150, bbox_inches='tight')
    plt.show()
    print(f"âœ… å›¾ç‰‡å·²ä¿å­˜: {FIGURE_DIR / 'cnn_training_history.png'}")


if __name__ == "__main__":
    print_config()
    
    # åŠ è½½æ•°æ®
    train_loader, test_loader, _, _ = load_data()
    
    # åŠ è½½é¢„è®­ç»ƒçš„è‡ªç¼–ç å™¨
    autoencoder = Autoencoder().to(DEVICE)
    autoencoder.load_state_dict(torch.load(MODEL_DIR / "autoencoder_best.pth"))
    print("âœ… å·²åŠ è½½é¢„è®­ç»ƒè‡ªç¼–ç å™¨")
    
    # è®­ç»ƒCNN
    model, history = train_cnn(train_loader, test_loader, autoencoder)
    plot_cnn_history(history)