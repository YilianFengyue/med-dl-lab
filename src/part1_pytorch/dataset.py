"""
æ•°æ®åŠ è½½æ¨¡å—
"""
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from config import *


def get_transforms(is_train=True):
    """è·å–æ•°æ®å˜æ¢ - å¼ºåŒ–ç‰ˆæ•°æ®å¢å¼º"""
    if is_train:
        # å¼ºæ•°æ®å¢å¼º - æœ‰æ•ˆæ‰©å……å°æ•°æ®é›†
        transform_list = [
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((IMG_SIZE + 20, IMG_SIZE + 20)),  # ç¨å¤§ä¸€ç‚¹ç”¨äºè£å‰ª
            transforms.RandomCrop((IMG_SIZE, IMG_SIZE)),  # éšæœºè£å‰ª
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.3),  # åŒ»å­¦å›¾åƒå¯ä»¥å‚ç›´ç¿»è½¬
            transforms.RandomRotation(degrees=15),
            transforms.RandomAffine(
                degrees=0,
                translate=(0.1, 0.1),  # å¹³ç§»
                scale=(0.9, 1.1),  # ç¼©æ”¾
                shear=5  # å‰ªåˆ‡
            ),
            transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.3),
            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),
            transforms.ToTensor(),
            transforms.RandomErasing(p=0.2, scale=(0.02, 0.1)),  # éšæœºæ“¦é™¤
        ]
    else:
        transform_list = [
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
        ]
    
    return transforms.Compose(transform_list)


def load_data():
    """åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†"""
    print("\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
    
    # è®­ç»ƒé›†
    train_transform = get_transforms(is_train=True)
    train_dataset = datasets.ImageFolder(
        root=str(TRAIN_DIR),
        transform=train_transform
    )
    train_loader = DataLoader(
        train_dataset,
        batch_size=AE_BATCH_SIZE,
        shuffle=True,
        num_workers=0,
        pin_memory=True,
        drop_last=True  # ä¸¢å¼ƒä¸å®Œæ•´çš„batchï¼Œç¨³å®šè®­ç»ƒ
    )
    
    # æµ‹è¯•é›†ï¼ˆå·²åŠ å™ªï¼‰
    test_transform = get_transforms(is_train=False)
    test_dataset = datasets.ImageFolder(
        root=str(TEST_DIR),
        transform=test_transform
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=len(test_dataset),  # ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æµ‹è¯•æ•°æ®
        shuffle=False,
        num_workers=0
    )
    
    # æ‰“å°æ•°æ®é›†ä¿¡æ¯
    print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾ç‰‡")
    print(f"âœ… æµ‹è¯•é›†: {len(test_dataset)} å¼ å›¾ç‰‡")
    print(f"ğŸ“Š ç±»åˆ«æ˜ å°„: {train_dataset.class_to_idx}")
    
    # ç»Ÿè®¡æ¯ç±»æ•°é‡å¹¶è®¡ç®—ç±»åˆ«æƒé‡
    class_counts = [0] * NUM_CLASSES
    for _, label in train_dataset:
        class_counts[label] += 1
    
    print(f"ğŸ“ˆ è®­ç»ƒé›†åˆ†å¸ƒ: {dict(zip(CLASS_NAMES, class_counts))}")
    
    # è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆåæ¯”äºæ ·æœ¬æ•°ï¼‰
    total = sum(class_counts)
    class_weights = [total / (NUM_CLASSES * c) for c in class_counts]
    class_weights = torch.FloatTensor(class_weights)
    print(f"âš–ï¸  ç±»åˆ«æƒé‡: {[f'{w:.2f}' for w in class_weights.tolist()]}")
    
    return train_loader, test_loader, train_dataset, test_dataset, class_weights


def add_noise(img, noise_factor=NOISE_FACTOR):
    """æ·»åŠ é«˜æ–¯å™ªå£°"""
    noisy_img = img + noise_factor * torch.randn_like(img)
    noisy_img = torch.clamp(noisy_img, 0., 1.)
    return noisy_img


if __name__ == "__main__":
    train_loader, test_loader, _, _, class_weights = load_data()
    print(f"\nç±»åˆ«æƒé‡: {class_weights}")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    for img, label in train_loader:
        print(f"Batch shape: {img.shape}, Labels: {label[:5]}")
        break