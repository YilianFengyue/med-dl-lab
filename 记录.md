# 基于自编码器和CNN的肺炎图像识别 - 实验报告总结

## 一、实验概述

**任务**：对肺部X光片进行三分类（Covid / Normal / Viral Pneumonia）  
**数据集**：训练集251张（干净图片），测试集66张（加高斯噪声）  
**核心挑战**：数据量极小 + 测试集带噪声

---

## 二、模型架构

### 整体Pipeline
```
噪声图片 → Autoencoder(去噪) → CNN(分类) → 三分类结果
```

### Autoencoder结构
```
编码器: Conv(1→32) → MaxPool → Conv(32→64) → MaxPool  [压缩]
解码器: Conv(64→32) → Upsample → Conv(32→32) → Upsample → Conv(32→1)  [重建]
```

### CNN结构 (V2/V3增强版)
```
特征提取: Conv(1→16)+BN+Dropout → Conv(16→32)+BN+Dropout → Conv(32→64)+BN+Dropout
全局池化: AdaptiveAvgPool(4×4)  [大幅减少参数]
分类器: Linear(1024→128)+BN+Dropout → Linear(128→32) → Linear(32→3)
```

---

## 三、三次迭代对比

| 版本 | 核心策略 | Accuracy | Normal Recall | 问题/改进 |
|------|----------|----------|---------------|-----------|
| **V1** | 基础CNN+简单增强 | 65.15% | 0.20 | 严重过拟合，Normal被误判为Viral |
| **V2** | BatchNorm+强数据增强+类别权重+Early Stopping | 68.18% | 0.35 | 过拟合解决，但AE丢失纹理特征 |
| **V3** | **端到端联合训练** | **81.82%** | **0.70** | AE学会保留分类关键特征 |

---

## 四、各版本详细设计

### V1 → V2 优化点

1. **解决过拟合**
   - 添加BatchNorm层（稳定训练）
   - 增加Dropout2d（卷积层正则化）
   - 全局平均池化（参数从16M→几十K）

2. **解决数据不足**
   - 强数据增强：RandomCrop、仿射变换、高斯模糊、随机擦除
   - 类别权重平衡（Normal/Viral权重提高到1.19）

3. **防止训练过度**
   - Early Stopping（patience=15）
   - 学习率调度（余弦退火）

### V2 → V3 优化点（核心突破）

**问题诊断**：  
V2的Normal Recall仅0.35，混淆矩阵显示45%的Normal被误判为Viral。  
**根因分析**：AE在去噪时把正常肺的纹理磨平了，看起来像"磨玻璃影"（Viral特征）。

**解决方案：端到端联合训练**

```python
# V2流程（有问题）
AE训练(MSE loss) → 冻结AE → CNN训练(CE loss)
#                    ↑ 断开了！AE不知道分类需要什么特征

# V3流程（修复）
联合训练: loss = CE(分类) + 0.1 * MSE(重建)
loss.backward()  # 梯度同时流向CNN和AE
#                  ↑ CNN告诉AE：保留这些纹理！
```

**技术细节**：
- 分层学习率：AE用0.00005（微调），CNN用0.0003（正常）
- 辅助重建损失：权重0.1，防止AE退化
- 梯度裁剪：max_norm=1.0，稳定训练

---

## 五、关键代码设计

### 端到端模型封装
```python
class EndToEndModel(nn.Module):
    def __init__(self, ae, cnn):
        super().__init__()
        self.ae, self.cnn = ae, cnn
    
    def forward(self, x, return_denoised=False):
        denoised = self.ae(x)
        logits = self.cnn(denoised)
        return (logits, denoised) if return_denoised else logits
```

### 联合损失函数
```python
loss_cls = CrossEntropyLoss(weight=class_weights)(logits, label)
loss_rec = MSELoss()(denoised, clean_data)
loss = loss_cls + 0.1 * loss_rec  # 分类为主，重建为辅
```

---

## 六、实验结果分析

### 最终性能 (V3)
- **Overall Accuracy**: 81.82%
- **Macro F1-Score**: 0.8092
- **分类报告**:

| 类别 | Precision | Recall | F1-Score |
|------|-----------|--------|----------|
| Covid | 0.89 | 0.92 | 0.91 |
| Normal | 0.88 | **0.70** | 0.78 |
| Viral | 0.70 | 0.80 | 0.74 |

### 关键改进证据
- Normal Recall: 0.20 → 0.35 → **0.70** （+250%）
- 混淆矩阵：Normal误判为Viral从13个降到6个

---

## 七、结论

1. **端到端训练显著优于分离训练**：在小样本场景下，让特征提取器(AE)和分类器(CNN)联合优化，能学到更有判别力的特征。

2. **正则化是小数据集的生命线**：BatchNorm + Dropout + 数据增强 + Early Stopping 缺一不可。

3. **类别不平衡需要主动处理**：类别权重让模型更关注少数类（Normal/Viral）。

4. **理论假设得到验证**：AE的"纹理磨平"问题通过端到端训练成功解决，Normal召回率大幅提升。

---

## 八、未来改进方向

| 方向 | 方法 | 预期收益 |
|------|------|----------|
| 换更强backbone | ResNet18预训练 | +10% |
| 高级数据增强 | Mixup/CutMix | +3-5% |
| 模型集成 | 多种子投票 | +2-3% |

---

*实验环境：PyTorch 2.5.1 + CUDA 12.1，GPU训练*